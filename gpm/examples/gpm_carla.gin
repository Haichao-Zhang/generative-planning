include 'gpm.gin'
include 'carla.gin'


import alf.algorithms.encoding_algorithm
import alf.networks.preprocessors
import alf.environments.carla_controller


activation = torch.relu_

#-----------ENV-----------


#-----------Train Params---------
num_env_steps=10000000
initial_collect_steps=1000
replay_buffer_length=100000

mini_batch_size=128
mini_batch_length=1 # for training
unroll_length=10

encoding_dim=256
rnn_critic_layer_size=256
gru_actor_hidden=256

fc_layers_params=(%encoding_dim, )



gru_critic_hidden_size=(%rnn_critic_layer_size, )

actor_fc_layers_params=(%gru_actor_hidden, )


actor/RecurrentNormalProjectionNetwork.use_res_delta=True


layer_size=256
fc_layer_params=(%layer_size, )
actor_fc_layers_params=(%layer_size, )




plan_length=20
num_of_anchors=3
min_target_commit_prob=10

lr=1e-4
init_epsilon=0


TrainerConfig.evaluate=0
TrainerConfig.eval_interval=2000


#----------------------
step_time=0.05
smooth_weight=1
action_to_world_conversion=1
GpInnerAlgorithm.use_entropy_reward=0
GpInnerAlgorithm.interp_method="linear"


projection_output_init_gain_mean=1e-5
projection_output_init_gain_std=1e-5


ReprLearner=@encoder/EncodingAlgorithm
GenerativePlanningAgent.representation_learner_cls=%ReprLearner

agent/AdamTF.lr=%lr

GenerativePlanningAgent.optimizer=@agent/AdamTF()



ActionSequenceOneStepWrapper.x_min=-20
ActionSequenceOneStepWrapper.x_max=20
ActionSequenceOneStepWrapper.y_min=-20
ActionSequenceOneStepWrapper.y_max=20
ActionSequenceOneStepWrapper.set_point_index=1
ActionSequenceOneStepWrapper.steps=%plan_length
ActionSequenceOneStepWrapper.delta_seconds_between_setpoints=%step_time
ActionSequenceOneStepWrapper.shrinkage_th=3
suite_carla.load.wrappers=[@ActionSequenceOneStepWrapper, @ActionObservationWrapper, @ScalarRewardWrapper]

ScalarRewardWrapper.reward_weights = [1., 0., 0., 0., 0., 0.]



VehicleController.max_throttle=1.0
VehicleController.max_steering=1.57
VehicleController.max_brake=1.0
VehicleController.target_speed_th=0.01



suite_carla.Player.steps=%plan_length


ActionSequenceOneStepWrapper.max_speed=20
suite_carla.Player.controller_ctor=@VehicleController





# config EncodingAlgorithm
encoder/EncodingNetwork.input_preprocessors=%input_preprocessors
encoder/EncodingNetwork.preprocessing_combiner=@NestSum(activation=%activation, average=True, nest_mask=%input_preprocessors_mask)
encoder/EncodingNetwork.activation=%activation
encoder/EncodingNetwork.fc_layer_params=%fc_layers_params
encoder/EncodingAlgorithm.encoder_cls=@encoder/EncodingNetwork


TrainerConfig.data_transformer_ctor=@agent/ImageScaleTransformer



agent/ImageScaleTransformer.min=0.0
agent/ImageScaleTransformer.fields=['observation.camera']

agent/ObservationNormalizer.clipping=5.0



suite_carla.Player.sparse_reward=False
suite_carla.Player.allow_negative_distance_reward=True


CarlaEnvironment.num_other_vehicles=20
CarlaEnvironment.num_walkers=20
CarlaEnvironment.vehicle_filter='vehicle.audi.tt'


suite_carla.Player.max_collision_penalty=20
suite_carla.Player.max_red_light_penalty=20
suite_carla.Player.overspeed_penalty_weight=0.
CarlaEnvironment.day_length=1000

#CarlaEnvironment.step_time=%step_time



# training config
TrainerConfig.debug_summaries=0
TrainerConfig.summarize_grads_and_vars=0
TrainerConfig.summary_interval=1000
TrainerConfig.summarize_action_distributions=False


TrainerConfig.evaluate=0
TrainerConfig.num_eval_episodes=20
TrainerConfig.eval_interval=5000



